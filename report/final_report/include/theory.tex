\section{Software Testing}
There are a lot different testing methods and the testing also varies
in different faces of the development life cycle. Software testing can
be divided into four different categories: correctness testing,
performance testing, reliability testing and security testing. This
thesis focuses of correctness testing. Correctness testing needs a set
of rules, which defines the behavior of the software. \cite{mellon}

\subsection{Random Testing}
When using random testing, test cases are simply selected at random
from the input domain. Random testing has been shown to be cost
efficient for a lot of programs. Subtle errors can be found at low
cost and random testing combined with other testing methods may result
in powerful and cost-effective testing solutions. \cite{mellon}

Random testing usually provides low code coverage because test cases
are uniformly distributed. As an example: To test an if-statement, which
compares equality of an 32-bits integer variable $v \in \mathbb{Z}_{32}$
to a fixed value $v_{comp} \in \mathbb{Z}_{32}$,
one must generate $v_{comp}$. Otherwise the if-statement will not evaluate to true.
If test cases are uniformly
chosen, the likelihood of generating $v_{comp}$ is $P = \frac{1}{2^{32}}$.
\cite{RandomTesting:Microsoft}

In white box testing, code knowledge can be added to the
generation of test cases. This can be done by narrowing the input domain
and thereby make it possible to drastically increase the number of needed test cases.
Sub domains, subsets of the input domain, can be chosen to represent both valid
conditions, as well as invalid conditions. In the example above, one sub domain
can consist of only the value $v_{comp}$. Another sub domain can be defined as
$\mathbb{Z}_{32}$\textbackslash$\{v_{comp}\}$, hence every other 32 bit integer.
Now only one test case is needed from each of the two sub
domains. The test case from $\{v_{comp}\}$ will make the if-statement evaluate to
true and the test case form $\mathbb{Z}_{32}$\textbackslash$\{v_{comp}\}$ will
make it evaluate to false.
\cite{RandomTesting:Revisited}

\subsection{Property Based Testing}
The purpose of property based testing is to establish formal
validation results through testing. Property based testing assumes
that the specified property captures everything of interest in the
program. This because of that property based testing only validates the
property. The property must hold whenever the program is
executed. \cite{Fink:1997:PTN:263244.263267}

A problem with testing is to figure out when enough testing has been
carried out. Property based testing solves this by performing an
iterative strategy. A test is negative if it violates the
property. The test is positive if a series of tests produces no errors
and the test is ``complete'' under some coverage metric. A test is
``incomplete'' if a series of tests passes, but is not complete
under the coverage metric. The iterative process comes from
continuously modifying the property and selecting test cases which
eventually makes the test
``complete''. \cite{Fink:1997:PTN:263244.263267}

Programs often consist of several independent properties, for example:
array bounds, race conditions and authentication. Such properties can
be put together as one property that should hold for the whole
program. Hence property based testing is very likely an iterative
process, where properties are put together until the test becomes
``complete''. \cite{Fink:1997:PTN:263244.263267}

\subsection{Model Based Testing}
Model based testing uses a model of a system to select test inputs
that tries to find test cases that explores the behavior of the
system. The output from the system can then be compared against the
model. The advent of model based testing has given rise to new
techniques that efficiently analyses system models with respect to the
behaviour of the systems requirements. Such techniques can for
instance find counter examples, when system requirements are
violated. The meaning of counter examples are concrete and
minimalistic cases when a system has an incorrect behavior with
respect to its requirements.
\cite{Meinke:ModelbasedTesting}

Model based testing makes it possible to manually select algorithms
that automatically and systematically generates test cases from a
model of the system.
\cite{Schieferdecker:ModelbasedTesting}

\subsection{Model Checking}
Model checking exhaustively checks the whole state space of a model that is
constructed for a system. Only the model of the system is checked and there are
no actual tests performed on the system. Instead the model is verified.  Model
checking uses properties, which generally can be classified into either
\emph{liveness} and \emph{safety}. Without formality \emph{liveness} means that eventually
some wanted behavior will happen and with \emph{safety} means that unwanted
behaviour will never happen. \cite{MODELCHECKING:SOFTWARE}

Model checking systems can be built on a finite state automata.  For instance the
verification tool SPIN, see \ref{SEC:EXISTING_TOOLS}, has such a model checking
system. \cite{HOLZMANN:SPIN}

\subsection{Model Checking vs Testing}
For larger system, when the state space is very large, it is more reasonable to
use testing since it is infeasible to test the whole state space. It is, however,
possible to extract certain parts of the system, which are considered important,
and construct a model for those parts, which could be formally verified using
model checking. \cite{MODELCHECKING:CLARKE}

\section{Formal Methods and Verification}
It is almost impossible to write a specification in a natural language
and not make room for different interpretations and
misunderstandings. Hence \emph{Formal Methods} are introduced which
are based on formal languages that have precise rules. Describing a
system with formal notation gives the ability of automating test cases
for the system, since it is precisely defined.  Formal methods can be
used everywhere in the development life cycle and not only when
writing specification for the whole system.
\cite[p.272]{COURSEBOOK:safety-critical}

In the ISO standard ISO~26262, see section \ref{SEC:ISO26262},
something called semi-formal notation is also mentioned. The
difference being that formal notation needs both semantics and syntax
to be well defined but semi-formal notation needs only the definition
of semantics. \cite{ISO26262:car}

To determine whether the output of a life cycle phase fulfills the
requirements specified by a previous phase, \emph{verification} is
needed. Formal verification is the verification of a system
using formal methods.  The exact meaning of verification is however
confusing. The definition may differ in comparison
of academic or industrial use. Even in different phases of the safety
life cycle verification is conducted in various forms.
\cite{thomas_arts}\cite[8:9.2]{ISO26262}\cite[p.309]{COURSEBOOK:safety-critical}

\section{Industrial Standards}

\subsection {IEC~61508 and ISO~26262}
\label{SEC:ISO26262}
IEC 61508 adopts a four level system for categorizing the severity of
hazards. It also adopts a six level system for classifying the
frequency of a hazard. There are four risk classes which are given the
values 1-4 where 1 corresponds to the most serious accidents and 4 to
the least serious. Based on this, IEC 61508 has a four level
classification of safety integrity levels called SIL, ranged from 1,
being the least critical, to 4, being the most critical. Each of the
safety integrity levels has a criteria of maximum frequency of
failures which a system built on that SIL must satisfy. In other
words, a SIL is a level of measure of the reliability of a safety
function.  Due to the fact that the failure of a safety function can
lead to a hazardous event, the safety integrity of a specific safety
function must be of such a level to ensure that the failure frequency
is sufficiently low or that the consequences of the hazardous event
are modified to meet a tolerable risk. To ensure safety, functions
with SIL 4 need to be tested and documented the most.
\cite{COURSEBOOK:safety-critical}\cite{IEC61508}\cite{Advances:IEC61508}\cite{Advances:SIL4}

The automotive functional safety standard, ISO~26262, has adopted a
similar system of safety integrity levels, called automotive safety
integrity levels or ASIL. As with IEC~61508 there are four integrity
levels, ranged A-D, but there are no direct correlation between the
two. \cite{TI:safety_critical}

ISO~26262 describes the full development process, from concept to
production, with functional safety in mind. For software development,
the standard has a reference model with different phases of the
process, see figure~\ref{FIG:ISO:phases}. Each phase in the reference
model is dependent on the earlier phases. The reference model has the
shape of a V, where the left side contains all development phases, and
the right side contains the test phases. The work flow from this view
starts with the phase ``specification of software safety
requirements''. This phase specifies the software requirements needed
to ensure the stability of the system. They are derived from the
system design specification. This is part of the integration between
software and hardware. The second phase is the ``software
architectural design''. It represents the interaction between all
software components. The third phase and the last development phase,
in the model is the ``software unit design and implementation''. This
phase contains the implementation of each module. If the
implementation does not meet the specified safety, the product needs
to go back to an earlier phase and be redesigned. \cite[6:5.4]{ISO26262}\cite[p.8-9]{COURSEBOOK:safety-critical}

\begin{figure}
  \includegraphics[keepaspectratio, width=\linewidth]{pictures/V}
  \caption{Phases of software development in the standard ISO~26262}
  \label{FIG:ISO:phases}
\end{figure}

Each of these phases is tested thoroughly with the phases ``software
unit testing'', ``software integration and testing'' and
``verification of software safety requirements''. The unit testing
phase confirms that the implementation of the module fulfills the
design specifications. If the product pass this phase, it continues to
the integration and testing phase, otherwise it is sent back to the
implementation phase. The objective in the phase software integration
and testing is to integrate the software units and demonstrate that
the architectural design is correct. A demonstration that the software
safety requirements is met, is performed in the phase ``verification
of software safety requirements''. \cite[6:5.4]{ISO26262}

\subsection{AUTOSAR (AUTomotive Open System ARchitecture)}
The AUTOSAR platform has a layered software architecture. This means
that the architecture is divided to a number of different layers, such
as the application layer, run-time environment, the basic software
layer, and the microcontroller. In the
figure~\ref{FIG:AUTOSAR:architecture} the basic software layer is
represented as four different parts; services, ECU abstraction,
microcontroller abstraction, and complex
drivers. \cite{AUTOSAR:LayeredSoftwareArchitecture}

\begin{figure}[!ht]
  \begin{center}
    \includegraphics[keepaspectratio, width=\linewidth]{pictures/autosar_architecture.jpg}
  \end{center}
  \caption{The AUTOSAR software architecture. Noticeable is that the basic
    software layer is divided further into four categories with even more subsections.}
  \label{FIG:AUTOSAR:architecture}
\end{figure}

The runtime environment is the operating system, and the
microcontroller is the hardware. The software running in the
application layer is for example software components for sensors and
actuators. One example of how the different parts in the basic
software layer is integrated, is the watchdog, which consists of
several parts as seen in figure~\ref{FIG:AUTOSAR:watchdog}. The
microcontroller abstraction layer has the drivers for the watchdog;
the interaction with the microcontroller. Then there is the watchdog
interface at the ECU abstraction layer. The watchdog interface is the
onboard device abstraction. Last is the watchdog manager (abbreviated
WdgM) which runs as a system service in the service layer. \cite{AUTOSAR:LayeredSoftwareArchitecture}

\begin{figure}[!ht]
  \begin{center}
    \includegraphics{pictures/watchdog_architecture.jpg}
  \end{center}
  \caption{The Watchdog and some other related modules.}
  \label{FIG:AUTOSAR:watchdog}
\end{figure}

The watchdog has a number of dependencies to other services in the
basic software layer. For example when an error is found by the
watchdog, it could either be reported to the diagnostic event manager
or the development error tracer depending on the type of error. These
are two services that are used for error management. \cite{SPEC:AUTOSAR:WDGM}

AUTOSAR's concept is to make it possible for vehicle manufacturers to
buy modules from different software developers, which will still work
together in unison. For a software developer to present a software
module with functionality that fits different vehicle manufacturers,
the standard introduces configurations. The configurations specifies a
number of parameters that can be configured in order to fit a specific
vehicle manufacture. In the watchdog manager for example, there is
parameters that specify if the watchdog manager should report errors
to the diagnostic event manager (DEM), or which type of supervision
that should be executed and what to supervise. \cite{AUTOSAR:basic_info}\cite{AUTOSAR:LayeredSoftwareArchitecture}

The current version of AUTOSAR, version 4, has been designed with
functional safety in mind. Essential concepts of ISO~26262 have been
developed alongside AUTOSAR. \cite{AUTOSAR:basic_info}

\section{Verification Methods}
The standard IEC~61508 propose two methods to formal verify a
program. The key is to model the program into one of the following
state transition models. \cite[p.127]{IEC61508}

\begin{enumerate}
\item \label{enum:FSM} Finite state machines/state transition diagrams
\item Timed Petri nets
\end{enumerate}

IEC~61508 emphasises that Timed Petri nets are best suited for
concurrent programs. Regarding the finite state machine method, the
following criteria needs to be satisfied for the implemented state
machine to be formal verified \cite[p.77-79]{IEC61508}\cite[p.322]{COURSEBOOK:safety-critical}:

\begin{description}
  \item[completeness] the system must have an action and new state for
    every input in every state,
  \item[consistency] only one state change is described for each
    state/input pair, and
  \item[reachability] whether or not it is possible to get from one
    state to another by any sequence of inputs.
\end{description}

If the state machine is correctly implemented it represents a correct
model of the original program. If it does not exist any unwanted
transitions or states, then the original program is formal verified.

Since most program specifications are written in natural languages
there may be a lot of ambiguities. Techniques have been developed to
reduce such cases, and these techniques are often referred to as semi
formal verification, because they often lack the mathematical rigor
associated with formal verification. These methods use textual,
graphical or other notation; often several techniques are used in
unity. \cite[p.91]{COURSEBOOK:safety-critical}

The description of semi formal verification in IEC~61508 states:
''Semi-formal methods provide a means of developing a description of a
system at some stage in its development, i.e. specification, design or
coding. The description can in some cases be analyzed by machine or
animated to display various aspects of the system behavior.'' \cite[p.77]{IEC61508}


\subsection{QuickCheck}
QuickCheck was invented by Koen Claessen and John Hughes, as a testing
module for Haskell in 2000. In 2006 John Hughes founded the company
Quviq together with Thomas Arts. Quviq offers a commercial version of
QuickCheck for Erlang. One of the main differences, except from the
programming language, is that the commercial version of QuickCheck has
a C-testing interface. Hence it is possible to test C-code in Erlang with
the help of QuickCheck. All test code is written in Erlang and checked
against API calls to the C-code, this is called model based
testing. It is not necessary to have the actual source code; it is
enough to only supply the compiled byte code and some library files of
the program to be able to test
it. \cite{QUVIQ:about}\cite{QUICKCHECK:manual}

QuickCheck uses property based testing, which means that system
requirements are implemented and tested as properties. QuickCheck
also makes use of random testing, but has guided random test
generation. This means that the samples can be weighted to cover
certain parts of the state space with more likelihood.
\cite{QUICKCHECK:manual}
