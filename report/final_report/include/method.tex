%% kolla att allt är i imperfekt
%% verb i passiv form

\section{Choose of tool for verification}
Software unit testing can be achieved by almost any tool.
%% motivera.
Consequently this phase is not the most interesting when it comes to the choose
of a tool verification. Of course one can take the simplicity to achieve good
%% "simplicity" - av vad?
unit testing into account, but still it is not what makes a verification tool
especially unique for the project goals.

Since the purpose is about benchmarking software the phase ''verification of
software safety requirements'' will not influence the choose. To be able to test
this phase, a greater amount of components of the whole system must be
available. Such components may include hardware etcetera. Implementation wise
%% "etcetera" borde arbetas bort.
should everything be able to run on a standard PC-machine.

The most interesting part is the software integration and testing. Is there a
tool that one can use to easily combine test and requirements from different
modules? Is it possible to test functional safety concept from this
combination, for example by corrupting some software elements?

\subsection{Why QuickCheck and Erlang?}

\section{Specification}
In AUTOSAR, specifications for each module is given in text form. Consequently
one must first, before a module can be tested, implement the specification for
that module in code.

\section{Testing}
%% vilka properties? quickcheck?
%% kanske är bättre att skriva "Module properties have to take..."
%% alternativt "Quickcheck properties for a module have to take..."
Properties for a module have to take the current state in consideration, since
most functions written in an imperative language are not immutable. This gives
raise to the idea of a state based testing tool.
%% .. och plötsligt: en lista:...
\begin{itemize}
\item Choose a specification which will be translated to QuickCheck properties
in parts.
\item With the use of statistics and confidence intervals, show that, with
enough tests the state-space will be exhausted.
\item Evaluate other semi formal techniques and show that the results from them
shows that QuickCheck is reliable for verification.
\item Generalize the technique.
\end{itemize}


\section{Choice of AUTOAR module to test}


\section{Implementation}
The C-code that was to be tested, using Quickcheck, was already unit tested and
already used in lab environments at Mecel. 

The behavior of the WdgM module was completely implemented in Erlang independent of 
the design choose of the C-code. This could be implemented
in an iterative way. Every piece of code was not required to be implemented before
any tests could be run. This because of that a module in AUTOSAR consist of several API
calls. Hence it was enough to only implement the specification for one API call
before tests could be run. Of course this gave rise to that only a part of 
the C-code could be tested. Also this early tests may not have fully tested the API
call because there may have been branches in the C-code, for this call, that
were never reached unless other API calls were called.

Early in the implementation face Quickcheck found differences between the Erlang
and C-implementation. This was expected because every programmer makes mistakes.
Hence the question arose who was faulty? The C-code or the Erlang code? Then
the API was thoroughly read and a conclusion was made. Either a bug in the
C-code was found or the Erlang-code needed to be corrected. There were however
cases when the API was ambiguous. In those cases the C-interpretation was chosen
as correct and the ambiguous specification written down. 

Surprisingly bugs in the C-code was found early, even though it already run
sharp in lab environments; only a few API calls needed to be implemented in Erlang. 

If a bug in the C-code was discovered how should the work be continued?  


A challenging step is the analysis of the results. If the testing tool returns zero
errors what does that say about the robustness of the input byte code? Passed
100 of 100 tests is just a statement and does not say anything more than that
some tests passed. Can tests be implemented in a clever way so that it is
possible to get some kind of confidence interval on the correctness of the code?

\begin{figure}[!ht]
\input{pictures/box.tex}
\caption{Abstract implementation module}
\end{figure}
